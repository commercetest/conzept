====== roadmap ======

===== general =====

  * Fix the items mentioned in **[[issues|issues]]**.

  * **[[architecture|Architectural]] vision**
    * Optimize the system for the user, to be: **accessible, in control, creative and fun.**
    * Work towards creating more **data-defined software... do more with less code.** This makes the software more 'malleable' and open-ended, for various contexts: [[datasources]], [[field_customization|fields]] (apps and websites), languages, custom functions (text-to-speech, bookmarking, etc.).
    * Improve and maintain **conceptual integrity** of how the various Conzept framework pieces fit together: [[datasources]], [[field customization|fields]], [[URL structure]], central configuration of common data across apps, easy intercommunication between apps, recursive Conzept views, 5D views (3D location + 1D time + 1D data-view).

  * Get more **engagement and feedback** from users and software developers.
    * What should and could be improved for them in the knowledge exploration and learning process?

===== AI =====

==== backend AI ====

LLM/Vector/Hybrid **AI powered, [[#backend search|backend-search]] using Typesense**. (see below)

==== frontend AI ====

[{{::llm_000.jpg?direct|LLM reasoning over multiple topics (bookmark titles) (using OpenAI) }}]

[{{::llm_001.jpg?direct|experiment with [[https://x.com/conzept__/status/1805977214007025690|structured LLM output]] (using OpenAI) }}]

Conzept's current vision for frontend [[explore>Large language model|LLM AI]], is to enhance and combine the strengths of these two search contexts: 

  * **Semantic search** - Due to using clear graph "entities" (regardless of language), the semantic web context is __often more rigid / safe / predictable / cheaper / faster / multi-lingual / correct / precise__, than Vector-based searches.

  * **Keyword / phrase based Vector-search** - this textual AI context is __often more flexible, fluid and creative__, than semantic-web style search context, but also requires a lot more compute/time.

If one starts with a more semantic grounding of LLM functionality, by using semantic "entities" (such as identifying Wikidata Qids for a topic), each topic will have a clear context, upon which you can start prompting the AI for the preferred action/intention.

Furthermore the combination of: [[https://www.promptingguide.ai/techniques/rag|Retrieval Augmented Generation]] (RAG), a vector DB, and a LLM model, can utilize this extra meta-data.

  * Candidate RAG tools:
    * [[https://github.com/nico-martin/ask-my-pdf|Ask-my-PDF]] (RAG + Vector DB + LLM QA)
    * [[https://github.com/poloclub/mememo|Mememo]] (RAG + Vector DB)

See the "structured LLM prompt" screenshot on the right, for an experiment of this. No text was typed by the user, the user only selected a bookmark to be used with some AI-based reasoning function. This makes it possible to combine topics, categorize the topics and also preface context to each topic, for the LLM prompt (in a multi-lingual way).

  * **[[https://conze.pt/app/web-llm-chat/out/|web-llm-chat]]**
    * **Conzept integration is a work in progress** (to replace the current, simple AI chat app)
      * Current status: Self-hosting is working, TODO: URL parameter context.
    * Features:
      * Fully client-side
      * Multi-model
      * WebGPU based
      * Multi-lingual (partly supported, open issues: [[https://github.com/mlc-ai/web-llm-chat/issues/46|parameter support]])
      * Multi-modal (not yet supported)
      * Application goals: Initially mainly focussed on text (and later other modalities, such as PDFs, audio and images).
    * Code:
      * [[https://github.com/mlc-ai/web-llm-chat|repo]]
      * [[https://github.com/mlc-ai/web-llm|web-llm]] (core framework)
    * Advantages of client-side AI models:
      * Privacy
      * Opensource
      * Cheaper operation (after the initial hardware purchase)
      * No 3rd-party AI-provider account needed
      * No limits on AI-queries (both quantitative and qualitative)
      * Flexibility and freedom how and where to use these AI models in the future.

  * **Main AI functions**:
    * Topical question-answering
    * Topical quizzing & examination
    * Content summarization and Q&A of larger texts (including PDFs)
    * Bookmark-selection reasoning (over one or more topics)
      * See also: [[https://x.com/conzept__/status/1805977214007025690|structured LLM output]]
      * make this reasoning fully multi-lingual (currently only a few languages)
    * Presentation augmentation (combined with TTS)
      * Add AI-entries (text + TTS) in the presentation table-of-contents

  * Similar projects:
    * [[https://github.com/abi/secret-llama|secret-llama]]
    * [[https://github.com/danny-avila/LibreChat|LibreChat]]
    * [[https://github.com/xenova/transformers.js/|Transformer.js]] (various)
    * [[https://github.com/nico-martin/ask-my-pdf|ask-my-pdf]] (pdf)
    * [[https://github.com/jacoblee93/fully-local-pdf-chatbot|pdf-chatbot]] (pdf)
    * [[https://github.com/reorproject/reor|reor]] (notes)

===== search =====

==== backend search ====

[{{::typesense_logo.jpg?direct|[[https://typesense.org|Typesense]] logo}}]

[{{::typesense_features.jpg?direct|[[https://typesense.org/docs/overview/features.html|Typesense features]]}}]

  * **Allow admins to create custom API-endpoints, for use as datasources** (from text, JSON, CSV or RDF). (work in progress)
    * [[https://typesense.org|Typesense]] (C++ based search-engine backend with LLM/Vector search support)
      * [[https://github.com/typesense|repo]]
      * [[https://typesense.org/docs/|docs]] ([[https://typesense.org/docs/26.0/api/|API spec]])

    * Allow both for **keyword** queries and **[[https://typesense.org/docs/26.0/api/vector-search.html|vector]]-based** queries (using a self-hosted LLM model).

    * Research Conzept integration, regarding:
      * The data-workflow (data files, insert/update/index scripts), for mulitple self-hosted datasources.
      * Add the Typesense-server + setup steps to the Conzept Docker install.

    * Experiment: Create an IPTV datasource using the Typesense-server.

  * Open issues:
    * Search-facets become possible for these Typesense-backed datasources (since we can view all results at once and extract the facets). Would it be a good idea to enable support for this when such a datasource is queried (and only that datasource)?

==== frontend search ====

  * Enhance temporal-range input (date-min, date-max) with an optional, **interactive date-range slider**.

  * Research feasability to **allow datasource searches without a search-term**, but with one or more search filters.

  * **Structured search** using SPARQL (beyond Wikidata)
    * Ontology classes
    * Ontology properties
    * Autocompletion
    * Multi-lingual labels
    * Handle CORS issues

  * Improve existing search modalities:
    * ? Wikidata: Allow for filtering by raw-text-strings in "structured search" (currently not supported in the Wikidata-query-builder)
    * Wikidata: Add **claim-support** to the Wikidata-data fetching (and support for claim-data in the field-definitions).

  * **Speech-based search input**
    * How to allow for multi-line text input?
    * How to combine speech-input with search commands?

  * **[[user_manual#search_commands|Search commands]]**
    * Currently this is used a little for AI-chat and simple mathematical graph plotting.
    * How could we combine this with multi-modal, client-side AI?
    * What other search-commands are needed?

===== datasources =====

  * **Improve existing datasources** (use more datasource meta-data, better content views, remove "BETA" label, etc.)

  * Research if it would be possible to **dynamically add datasource-specific filter-types** (only when a single datasource is active!).
    * This would allow for more fine-grained search type-filters, finetuned to a particular datasource.
    * Eg. for library/book datasources: Author, Title, Publisher, Genre, Topic, Resource-location, ISBN/Some-ID, Availability, Legal-rights, ...

  * Consider adding **multi-select for datasource sets**.

  * Consider adding a **new global filter: "people"** (which is quite common, and more specific than "entities").

  * Implement **async data-enriching in datasources** (work in progress)
    * This would eg. allow 3rd-party datasources with a Wikidata Qid (or some other related ID with metadata) in their results, to be enriched.

  * Implement **json-proxy support for HTTP header Authorization** (using the key from settings.conf)
    * To check: That the used header (on the frontend) is working for eg. CourtListener

  * **Indepent active/autocomplete/search toggles per datasource**. Eg. to allow for searching Wikipedia concepts in other datasources). More control over how datasources are used, with toggle-switches for:
    * datasource is active (boolean toggle)
      * datasource autocomplete (boolean toggle)
      * datasource searching (boolean toggle)

===== presentation system =====

  * Allow for **presentation to be build from Conzept fields**
    * design reuirements: auto-positioning slides, handle the common start/end slides sets, ...

  * Allow for extra Text-to-Speech (TTS) storylines around a topic (beyond Wikipedia and Wikidata information). 
    * Related books, science articles (partly done), AI-generated summaries and other content, AI explain text selection, ...? 

  * Allow for **bookmarking presentations**

===== browser extension =====

  * **Re-implement the Conzept extension** with [[https://developer.chrome.com/docs/extensions/mv3/intro/|Manifest v3]] support (MV3). This is a requirement for the Chrome extension store.
    * Maybe look into using the [[https://github.com/PlasmoHQ/plasmo|Plasmo]] browser extension framework.
    * Goal: Provide a right-click menu-option to search on Conzept (make it work in embedded iframes and perhaps PDFs too, if possible)

===== bookmarks =====

  * **Bookmarking**:
    * Cross-tab bookmark state-syncing
    * Allow for bookmarking presentations
    * Bookmark edit mode -> then click on bookmark -> display bookmark edit modal -> save button
    * Better generic data support, based on the "item data object"
    * Add more input-formats:
      * images (experimental support)
      * drawings (using tldraw or excalidraw)
      * speech-to-text transcript ([[https://github.com/LittlePath/live-transcript|webcomponent]])
      * audio ([[https://github.com/LittlePath/audio-recorder|webcomponent]])
      * video ([[https://github.com/LittlePath/video-recorder|webcomponent]])
      * longer notes
      * ? PDF
    * Research better drag-and-drop support

===== admin-dev workflows =====

  * Improve the workflow for adding [[datasources]].
    * There are some minor manual issues, when adding new datasources which can be automated/scripted away.
    * The "datasources.js" function-calls can be cleanup in a few places.

  * **Field-translation support**: Create a structure to store field-label translations (title and icon-title), both for Wikidata and non-Wikidata fields.
    * Allow the [[adding_new_wikidata_properties|json2fields]] script to fetch and store property translations too.

  * Add a **test-framework** -> start adding tests for the most essential / complex code parts

  * How to detect if the field URL could be embedded (instead of opening a a new tab)? (run a headless browser loading an iframe with the URL, checking for CORS-errors?)

===== performance =====

  * Add **webworker-support** and move (more and more) non-UI functionality to these workers.
    * Research: What would be a good incremental approach (and framework) for adding this?

===== educational-support  =====

  * **Collaborative & social learning** features:
    * shared audio and chat (eg. [[https://github.com/lyricat/mornin.fm|p2p audio-chat]] and [[https://www.hyperhyperspace.org/|text-chat]] rooms for each topic)
  * **Quizzing**: Auto-generated, [[https://fs.blog/spacing-effect/|spaced-repetition]]-based facts learning (for a certain topic / set of topics / topic-domain)
  * **Experiencing / Simulating**: eg. play Chess positions (done), ...
  * ? Note-taking integration  (eg.: [[https://bangle.io/|Bangle]], ...)
  * Better ways to indicate personal and professional interests (similar to the persona-tags setting)

